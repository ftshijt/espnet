# codec example yaml config

# discrete speech metrics
# -- speech_bert: speech bert score
# -- speech_bleu: speech bleu score
# -- speech_token_distance: speech token distance score
# - name: discrete_speech_metric

# pseudo subjective metrics
# -- utmos: UT-MOS score
# -- dnsmos: DNS-MOS score
# -- plcmos: PLC-MOS score
# -- aecmos: AEC-MOS score
- name: pseudo_mos
  predictor_types: ["utmos", "dnsmos"]
  predictor_args:
    utmos:
      fs: 16000
    dnsmos:
      fs: 16000

- name: signal_metric

# pesq related metrics
# -- pesq: perceptual evaluation of speech quality
- name: pesq


# Word error rate with OpenAI-Whisper model
# More model_tag can be from https://github.com/openai/whisper?tab=readme-ov-file#available-models-and-languages .
# The default model is `large-v3`.
# NOTE(jiatong): further aggregation are necessary for corpus-level WER/CER
# --whisper_hyp_text: the hypothesis from ESPnet ASR decoding
# --ref_text: reference text (after cleaner)
# --whisper_wer_delete: delete errors
# --whisper_wer_insert: insertion errors
# --whisper_wer_replace: replacement errors
# --whisper_wer_equal: correct matching words/character counts
# --whisper_cer_delete: delete errors
# --whisper_cer_insert: insertion errors
# --whisper_cer_replace: replacement errors
# --whisper_cer_equal: correct matching words/character counts
- name: whisper_wer
  model_tag: default
  beam_size: 1
  text_cleaner: whisper_en

# speaker related metrics
# -- spk_similarity: speaker cosine similarity
- name: speaker
  model_tag: default
